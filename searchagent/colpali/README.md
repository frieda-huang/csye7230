This is a wrapper on [colpali](https://github.com/illuin-tech/colpali/tree/main): Code used for training the vision retrievers in the ColPali: Efficient Document Retrieval with Vision Language Models paper

## ViDoRe: The Visual Document Retrieval Benchmark

-   https://huggingface.co/spaces/vidore/vidore-leaderboard

## Relevant Readings

-   [ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT
    ](https://arxiv.org/abs/2004.12832)
-   [ColPali: Efficient Document Retrieval with Vision Language Models
    ](https://arxiv.org/abs/2407.01449)
-   [What is ColBERT and Late Interaction and Why They Matter in Search?](https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/)
-   [Scaling ColPali to billions of PDFs with Vespa](https://blog.vespa.ai/scaling-colpali-to-billions/)
-   [A notebook utilizing Vespa to store embeddings generated by ColPali](https://pyvespa.readthedocs.io/en/latest/examples/colpali-document-retrieval-vision-language-models-cloud.html)
-   [Scalar and binary quantization for pgvector vector search and storage](https://jkatz05.com/post/postgres/pgvector-scalar-binary-quantization/)

## Relevant GitHub Repos

-   [byaldi](https://github.com/AnswerDotAI/byaldi): A lightweight wrapper around the `colpali-engine`

## Improvement

-   Extract text from PDFs and use LLM to generate summary for each file
-   Use approximate search
-   Improve memory efficiency by dividing each embedding into sub-vectors.
-   Use IVFPQ (Inverted File with Product Quantization)

## Vector Database

-   We use pgvector, a PostgreSQL extension, to store embeddings (specifically multiple vectors).
-   We use the technique [here](https://github.com/pgvector/pgvector-python/blob/master/examples/colbert/exact.py) to do exact search.
-   For approximate search, we store each vector in a separate row and use the approach described in Section 3.6 of the ColBERT paper.
    -   Instead of applying MaxSim, we can use faiss. At the end of online indexing, we maintain a mapping from each embedding to its document of origin and then index all document embeddings into faiss.
    -   When serving queries, we use two-stage procedure to retrieve the top-k documents from the entire collection.
        -   Approximate stage aimed at filtering
            -   For example:
                Given a query (represented by 10 vectors, denoted by Nq = 10), each vector retrieves 50 similar vectors; then total retrieved documents will be 10 x 50 = 500 document IDs (before duplication). After duplication, we might obtain k unique documents. We have duplicates because each vector of a query can retrieve similar vectors that point to the same documents.
        -   Refinement stage
            -   re-ranking k documents based on more precise scoring mechanisms like ColBERT's scoring.

## Common Issues Dealing With pgvector and Multiple Vectors

-   https://github.com/pgvector/pgvector/issues/640
-   https://github.com/pgvector/pgvector-python/issues/96
-   https://github.com/pgvector/pgvector-python/issues/50
-   https://github.com/pgvector/pgvector-python/issues/4
