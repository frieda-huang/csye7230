{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['context', 'question', 'answer', 'source_doc', 'groundedness_score',\n",
       "        'groundedness_eval', 'relevance_score', 'relevance_eval',\n",
       "        'standalone_score', 'standalone_eval'],\n",
       "       dtype='object'),\n",
       " Index(['question', 'true_answer', 'source_doc', 'generated_answer',\n",
       "        'retrieved_docs', 'test_settings', 'eval_score_Llama3.1',\n",
       "        'eval_feedback_Llama3.1', 'settings'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from searchagent.utils import project_paths\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "datadir = project_paths.DATA / \"synthetic_testdata\"\n",
    "eval_dataset_df = pd.read_csv(datadir / \"m-ric~huggingface_doc_347.csv\")\n",
    "eval_results_df = pd.read_csv(project_paths.EVAL_OUTPUT / \"evaluation_results.csv\")\n",
    "\n",
    "\n",
    "eval_dataset_df.columns, eval_results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    347.000000\n",
       "mean       0.703170\n",
       "std        0.318284\n",
       "min        0.000000\n",
       "25%        0.500000\n",
       "50%        0.750000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: eval_score_Llama3.1, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the statistics on eval_score_Llama3.1\n",
    "col_name = \"eval_score_Llama3.1\"\n",
    "stats = eval_results_df[col_name].describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7031700288184438"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our baseline performance\n",
    "average_scores = eval_results_df[col_name].mean()\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
